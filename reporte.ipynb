{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "PROD_CONCAT = \"ProdConcat\"\n",
    "COSTO_COMPRA = \"Costo Compra\"\n",
    "CANTIDAD_COMPRA = \"Cantidad Compra\"\n",
    "PRECIO_VENTA = \"Precio Venta\"\n",
    "UTILIDAD = \"UTILIDAD_%\"\n",
    "IVA = .16\n",
    "CIEN = 100\n",
    "\n",
    "CLASIFICACION = \"CLASIFICACION\"\n",
    "N1 = \"N1\"\n",
    "N2 = \"N2\"\n",
    "N3 = \"N3\"\n",
    "\n",
    "def unir_dataframes(lista_df):\n",
    "    \"\"\"\n",
    "    Une una lista de DataFrames en uno solo, validando que todos tengan las mismas columnas.\n",
    "\n",
    "    :param lista_df: Lista de DataFrames a unir.\n",
    "    :return: DataFrame combinado si todos los DataFrames tienen las mismas columnas.\n",
    "    :raises ValueError: Si los DataFrames no tienen las mismas columnas.\n",
    "    \"\"\"\n",
    "    # Validar que la lista no esté vacía\n",
    "    if not lista_df:\n",
    "        raise ValueError(\"La lista de DataFrames está vacía.\")\n",
    "    \n",
    "    # Obtener las columnas del primer DataFrame como referencia\n",
    "    columnas_referencia = lista_df[0].columns\n",
    "    \n",
    "    # Verificar que todos los DataFrames tengan las mismas columnas\n",
    "    for i, df in enumerate(lista_df):\n",
    "        if not df.columns.equals(columnas_referencia):\n",
    "            raise ValueError(f\"El DataFrame en la posición {i} no tiene las mismas columnas.\")\n",
    "    \n",
    "    # Concatenar los DataFrames si pasan la validación\n",
    "    df_resultado = pd.concat(lista_df, ignore_index=True)\n",
    "    return df_resultado\n",
    "\n",
    "def generar_excel_by_dataframe(df, nombre_base):\n",
    "    \"\"\"\n",
    "    Genera un archivo Excel a partir de un DataFrame, añadiendo la fecha y hora actual al nombre del archivo.\n",
    "    :param df: DataFrame a exportar.\n",
    "    :param nombre_base: Nombre base del archivo (sin extensión).\n",
    "    :return: Ruta completa del archivo generado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYYMMDD_HHMMSS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre del archivo\n",
    "        nombre_archivo = f\"{nombre_base}_{fecha_hora}.xlsx\"\n",
    "        \n",
    "        # Exportar el DataFrame a Excel\n",
    "        df.to_excel(nombre_archivo, index=False, engine=\"openpyxl\")\n",
    "        \n",
    "        print(f\"Archivo Excel generado exitosamente: {nombre_archivo}\")\n",
    "        return nombre_archivo\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar el archivo Excel: {e}\")\n",
    "        return None\n",
    "\n",
    "def archivos_excel_by_coincidencia(directorio: str, cadena: str):\n",
    "    archivos_excel = []\n",
    "    patron = f\"*{cadena}*.xlsx\"\n",
    "    \n",
    "    for archivo in os.listdir(directorio):\n",
    "        if fnmatch.fnmatch(archivo, patron):\n",
    "            archivos_excel.append(archivo)\n",
    "\n",
    "    return archivos_excel\n",
    "    \n",
    "def filtrar_columnas_dataframe(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Devuelve un DataFrame que contiene solo las columnas especificadas.\n",
    "\n",
    "    :param dataframe: DataFrame de pandas del que se desea conservar las columnas.\n",
    "    :param columnas: Lista de nombres de columnas a conservar.\n",
    "    :return: DataFrame con solo las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar cuáles columnas existen en el DataFrame\n",
    "        columnas_existentes = [col for col in columnas if col in dataframe.columns]\n",
    "        columnas_no_existentes = [col for col in columnas if col not in dataframe.columns]\n",
    "\n",
    "        if columnas_no_existentes:\n",
    "            print(f\"Las siguientes columnas no existen en el DataFrame: {columnas_no_existentes}\")\n",
    "\n",
    "        # Columnas filtradas\n",
    "        dataframe = dataframe[columnas_existentes]\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error al intentar filtrar las columnas: {e}\")\n",
    "\n",
    "    return dataframe\n",
    "    \n",
    "def validar_datos_numericos_dataframe(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Reemplaza ceros en las columnas especificadas de un DataFrame con NaN.\n",
    "    :param dataframe: DataFrame en el que se procesarán las columnas.\n",
    "    :param columnas: Lista de nombres de columnas donde se reemplazarán los ceros por NaN.\n",
    "    :return: DataFrame con los ceros reemplazados por NaN en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas existan en el DataFrame\n",
    "        columnas_validas = [col for col in columnas if col in dataframe.columns]\n",
    "        # Reemplazar ceros por NaN en las columnas válidas\n",
    "        dataframe[columnas_validas] = dataframe[columnas_validas].replace(0, np.nan)\n",
    "        print(f\"Ceros reemplazados por NaN en las columnas: {columnas_validas}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al reemplazar ceros por NaN: {e}\")\n",
    "    return dataframe\n",
    "    \n",
    "def crear_carpeta(base_nombre_carpeta, ruta_base=\".\"):\n",
    "    \"\"\"\n",
    "    Crea una carpeta con un nombre que incluye la fecha y hora actual al final.\n",
    "    \n",
    "    :param base_nombre_carpeta: Nombre base para la carpeta.\n",
    "    :param ruta_base: Ruta donde se creará la carpeta. Por defecto, en el directorio actual.\n",
    "    :return: Ruta completa de la carpeta creada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYY-MM-DDTHH-MM-SS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre completo de la carpeta\n",
    "        nombre_completo_carpeta = f\"{base_nombre_carpeta}_{fecha_hora}\"\n",
    "        ruta_completa_carpeta = os.path.join(ruta_base, nombre_completo_carpeta)\n",
    "        \n",
    "        # Crear la carpeta\n",
    "        os.makedirs(ruta_completa_carpeta, exist_ok=True)\n",
    "        print(f\"Carpeta creada: {ruta_completa_carpeta}\")\n",
    "        return ruta_completa_carpeta\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear la carpeta: {e}\")\n",
    "        return None\n",
    "\n",
    "def mover_archivos_a_carpeta(lista_archivos, carpeta_destino):\n",
    "    \"\"\"\n",
    "    Mueve una lista de archivos a una carpeta destino.\n",
    "    :param lista_archivos: Lista con las rutas de los archivos a mover.\n",
    "    :param carpeta_destino: Ruta de la carpeta destino.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear la carpeta destino si no existe\n",
    "        carpeta_destino = crear_carpeta(carpeta_destino)\n",
    "        for archivo in lista_archivos:\n",
    "            if os.path.isfile(archivo):  # Verificar que el archivo existe\n",
    "                destino = os.path.join(carpeta_destino, os.path.basename(archivo))  # Ruta destino\n",
    "                shutil.move(archivo, destino)  # Mover el archivo\n",
    "                print(f\"Archivo movido: {archivo} -> {destino}\")\n",
    "            else:\n",
    "                print(f\"El archivo no existe: {archivo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al mover archivos: {e}\")\n",
    "\n",
    "def validar_archivos(lista_archivos):\n",
    "    \"\"\"\n",
    "    Valida que una lista de archivos no contenga valores vacíos.\n",
    "    :param lista_archivos: Lista de rutas de archivos.\n",
    "    :return: True si todos los archivos son válidos, False si hay archivos faltantes.\n",
    "    \"\"\"\n",
    "    # Filtrar archivos vacíos\n",
    "    archivos_faltantes = [archivo for archivo in lista_archivos if archivo == \"\"]\n",
    "    \n",
    "    if archivos_faltantes:\n",
    "        print(\"Error: Faltan archivos necesarios para el proceso del reporte.\")\n",
    "       \n",
    "    \n",
    "    print(\"Todos los archivos son válidos.\")\n",
    "    return True\n",
    "\n",
    "def validar_listas_archivos_no_vacias(lista_de_listas):\n",
    "    \"\"\"\n",
    "    Valida que ninguna lista dentro de una lista de listas esté vacía.\n",
    "    \n",
    "    :param lista_de_listas: Lista de listas de strings.\n",
    "    :return: True si ninguna lista está vacía.\n",
    "    :raises ValueError: Si alguna lista está vacía.\n",
    "    \"\"\"\n",
    "    for i, lista in enumerate(lista_de_listas):\n",
    "        if not lista:  # Verifica si la lista está vacía\n",
    "            print(\"Error: Faltan archivos necesarios para el proceso del reporte.\")\n",
    "            sys.exit(1)  # Rompe la ejecución con un código de error\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def crear_dataframe_from_excel(archivo: str, columnas: list = None, hoja: str = None):\n",
    "    \"\"\"\n",
    "    Lee un archivo de Excel y crea un DataFrame filtrado con las columnas especificadas.\n",
    "\n",
    "    :param archivo: Ruta del archivo Excel a leer.\n",
    "    :param columnas: Lista de nombres de columnas que se desean extraer del archivo.\n",
    "    :param hoja: Nombre de la hoja a leer. Si no se especifica, se lee la primera hoja por defecto.\n",
    "    :return: DataFrame con las columnas filtradas, o None si ocurre un error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Inicializar el DataFrame\n",
    "        df = None\n",
    "        # Leer el archivo de Excel\n",
    "        # Si no se especifica una hoja, se lee la primera por defecto\n",
    "        if hoja is None:\n",
    "            df = pd.read_excel(archivo, engine='openpyxl')\n",
    "        else:\n",
    "            # Si se especifica una hoja, se intenta leer esa hoja en particular\n",
    "            df = pd.read_excel(archivo, engine='openpyxl', sheet_name=hoja)\n",
    "        # Filtrar las columnas especificadas por el usuario\n",
    "        if columnas:\n",
    "            df = df[columnas]\n",
    "        # Devolver el DataFrame filtrado\n",
    "        return df\n",
    "    # Manejo de excepciones\n",
    "    except FileNotFoundError:\n",
    "        # Error si el archivo no se encuentra en la ruta especificada\n",
    "        print(f\"El archivo {archivo} no fue encontrado.\")\n",
    "    except KeyError as e:\n",
    "        # Error si una o más columnas no existen en el archivo\n",
    "        print(f\"Una o más columnas no se encuentran en el archivo: {e}\")\n",
    "    except ValueError:\n",
    "        # Error si la hoja especificada no existe en el archivo\n",
    "        print(f\"La hoja '{hoja}' no existe en el archivo {archivo}.\")\n",
    "    except Exception as e:\n",
    "        # Captura cualquier otro error no previsto\n",
    "        print(f\"Se produjo un error al procesar el archivo: {e}\")\n",
    "\n",
    "def crear_dataframe_unido_por_coincidencia_excel(directorio: str = \"./\", cadena: str = \"\", columnas: list = None, hoja: str = None):\n",
    "    \"\"\"\n",
    "    Busca archivos Excel en un directorio que coincidan con una cadena en su nombre, \n",
    "    los convierte en DataFrames (opcionalmente filtrando columnas y seleccionando una hoja específica)\n",
    "    y los une en un solo DataFrame.\n",
    "\n",
    "    :param directorio: Ruta del directorio donde buscar archivos Excel (por defecto \"./\").\n",
    "    :param cadena: Cadena de coincidencia para buscar archivos.\n",
    "    :param columnas: Lista de columnas a seleccionar de cada archivo (opcional). Si no se proporciona, se cargan todas.\n",
    "    :param hoja: Nombre de la hoja a leer (opcional). Si no se proporciona, se lee la primera hoja.\n",
    "    :return: DataFrame unido de todos los archivos encontrados y leídos correctamente.\n",
    "    :raises FileNotFoundError: Si no se encuentra ningún archivo que coincida con la búsqueda.\n",
    "    :raises ValueError: Si no se pudieron leer archivos o unir DataFrames correctamente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar archivos Excel en el directorio que contengan la cadena en su nombre\n",
    "    archivos_coincidentes = archivos_excel_by_coincidencia(directorio, cadena)\n",
    "    \n",
    "    # Si no se encuentran archivos, lanzar un error\n",
    "    if not archivos_coincidentes:\n",
    "        raise FileNotFoundError(f\"No se encontraron archivos que coincidan con '{cadena}' en {directorio}.\")\n",
    "\n",
    "    # Lista para almacenar los DataFrames generados a partir de los archivos encontrados\n",
    "    lista_df = []\n",
    "\n",
    "    # Iterar sobre cada archivo encontrado\n",
    "    for archivo in archivos_coincidentes:\n",
    "        ruta_completa = os.path.join(directorio, archivo)  # Crear la ruta completa del archivo\n",
    "        \n",
    "        try:\n",
    "            # Crear un DataFrame a partir del archivo Excel, con la opción de filtrar columnas y seleccionar hoja\n",
    "            df = crear_dataframe_from_excel(archivo=ruta_completa, columnas=columnas, hoja=hoja)\n",
    "            lista_df.append(df)  # Añadir el DataFrame a la lista\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Capturar errores durante la lectura de los archivos\n",
    "            print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "    \n",
    "    # Si hay DataFrames válidos en la lista, unirlos\n",
    "    if lista_df:\n",
    "        return unir_dataframes(lista_df)\n",
    "    \n",
    "    # Si no se pudieron leer los archivos correctamente, lanzar un error\n",
    "    else:\n",
    "        raise ValueError(\"No se pudieron leer los archivos correctamente.\")\n",
    "\n",
    "def ordenar_columnas_al_lado(df, columna_referencia, columnas_a_mover):\n",
    "    \"\"\"\n",
    "    Ordena una lista de columnas al lado de una columna de referencia en un DataFrame.\n",
    "\n",
    "    :param df: DataFrame a modificar.\n",
    "    :param columna_referencia: Columna donde se insertarán las demás columnas al lado.\n",
    "    :param columnas_a_mover: Lista de columnas que se deben mover al lado de la columna de referencia.\n",
    "    :return: DataFrame con las columnas reordenadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas estén en el DataFrame\n",
    "        columnas_faltantes = [col for col in columnas_a_mover + [columna_referencia] if col not in df.columns]\n",
    "        if columnas_faltantes:\n",
    "            raise ValueError(f\"Las siguientes columnas no están en el DataFrame: {columnas_faltantes}\")\n",
    "\n",
    "        # Obtener la lista de columnas actuales\n",
    "        columnas_actuales = df.columns.tolist()\n",
    "\n",
    "        # Determinar la posición de la columna de referencia\n",
    "        indice_referencia = columnas_actuales.index(columna_referencia)\n",
    "\n",
    "        # Crear una nueva lista de columnas manteniendo el orden original\n",
    "        nuevas_columnas = []\n",
    "        for col in columnas_actuales:\n",
    "            if col == columna_referencia:\n",
    "                # Insertar la columna de referencia\n",
    "                nuevas_columnas.append(col)\n",
    "                # Insertar las columnas a mover justo después de la columna de referencia\n",
    "                nuevas_columnas.extend([c for c in columnas_a_mover if c in columnas_actuales])\n",
    "            elif col not in columnas_a_mover:\n",
    "                # Mantener otras columnas que no se están moviendo\n",
    "                nuevas_columnas.append(col)\n",
    "\n",
    "        # Reordenar el DataFrame con las nuevas columnas\n",
    "        df = df[nuevas_columnas]\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al reordenar las columnas: {e}\")\n",
    "        return df  # Devolver el DataFrame original en caso de error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_dataframe_ventas():\n",
    "    columnas_ventas_acc_tel = [\"Almacen\", \"ProdConcat\", \"Cantidad\", \"PrecioVenta\", N1, N2, N3]\n",
    "    df_ventas_acc_tel = crear_dataframe_unido_por_coincidencia_excel(directorio=\"./Ventas\", cadena=\"Analisis de Ventas\", columnas=columnas_ventas_acc_tel)\n",
    "    df_ventas_acc_tel = validar_datos_numericos_dataframe(df_ventas_acc_tel, [\"Cantidad\",\"PrecioVenta\"])\n",
    "\n",
    "    columnas_ventas_refacc = [\"Almacén Salida Reparación\", \"Producto\", \"Cantidad\", \"PrecioVentaSinIva\", N1, N2, N3]\n",
    "    df_ventas_refacc = crear_dataframe_unido_por_coincidencia_excel(directorio=\"./Ventas\", cadena=\"Refacciones_Consumidas\", columnas=columnas_ventas_refacc)\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_refacc = {\n",
    "        \"Almacén Salida Reparación\": \"Almacen\",\n",
    "        \"Producto\": \"ProdConcat\",\n",
    "        \"PrecioVentaSinIva\": \"PrecioVenta\"\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_ventas_refacc.rename(columns=mapeo_columnas_refacc, inplace=True)\n",
    "    df_ventas_refacc = validar_datos_numericos_dataframe(df_ventas_refacc, [\"Cantidad\",\"PrecioVenta\"])\n",
    "    # Calcular el 16% y sumarlo a la columna Costo_Compra\n",
    "    df_ventas_refacc[\"PrecioVenta\"] = df_ventas_refacc[\"PrecioVenta\"]+(df_ventas_refacc[\"PrecioVenta\"]*IVA)\n",
    "    #Fusionamos las ventas de accesorios, telefonía y refacciones\n",
    "    return unir_dataframes([df_ventas_acc_tel, df_ventas_refacc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_ventas_pivot_almacen(df_ventas):\n",
    "    # Agrupar por 'Almacen' y 'ProdConcat'\n",
    "    df_ventas_agrupado = df_ventas.groupby(['Almacen', 'ProdConcat']).agg({\n",
    "        'Cantidad': 'sum',                 # Sumar las cantidades\n",
    "        'PrecioVenta': 'mean'              # Promediar el precio de venta\n",
    "    }).reset_index()  # Resetear el índice para mantener las columnas de agrupación\n",
    "\n",
    "    \n",
    "    # Paso 2: Pivoteo por 'ProdConcat' y 'Almacen'\n",
    "    pivot_ventas = df_ventas_agrupado.pivot_table(\n",
    "        index=\"ProdConcat\", \n",
    "        columns=\"Almacen\", \n",
    "        values=\"Cantidad\", \n",
    "        aggfunc=\"sum\"  # Ya no debería ser necesario, pero lo dejamos por seguridad\n",
    "    )\n",
    "\n",
    "    # Paso 3: Renombrar las columnas del pivote agregando un prefijo\n",
    "    pivot_ventas = pivot_ventas.rename(columns=lambda col: f\"Ventas de {col}\")\n",
    "\n",
    "    # Paso 4: Convertir el índice del pivote a una columna para un DataFrame plano\n",
    "    return pivot_ventas.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_ventas_totales(df_ventas):\n",
    "    df_ventas = filtrar_columnas_dataframe(df_ventas, [PROD_CONCAT, \"Cantidad\", \"PrecioVenta\", N1, N2, N3])\n",
    "     # Agrupar por 'Almacen' y 'ProdConcat'\n",
    "    df_ventas_agrupado = df_ventas.groupby(['ProdConcat']).agg({\n",
    "        'Cantidad': 'sum',                 # Sumar las cantidades\n",
    "        'PrecioVenta': 'mean',\n",
    "        N1: 'first',\n",
    "        N2: 'first',\n",
    "        N3: 'first'\n",
    "    }).reset_index()  # Resetear el índice para mantener las columnas de agrupación\n",
    "\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_ventas = {\n",
    "        \"Cantidad\": \"Venta Global\",\n",
    "        \"PrecioVenta\": PRECIO_VENTA\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_ventas_agrupado.rename(columns=mapeo_columnas_ventas, inplace=True)\n",
    "\n",
    "    return df_ventas_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_dataframe_compras():\n",
    "    columnas_compras = [\"Almacen\", \"Producto\", \"Costo\", \"Cantidad\"]\n",
    "    df_compras = crear_dataframe_unido_por_coincidencia_excel(directorio=\"./Compras\", cadena=\"Excel_Movimientos\", columnas=columnas_compras, hoja=\"Detalle de movimientos\")\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_compras = {\n",
    "        \"Producto\": PROD_CONCAT,\n",
    "        \"Costo\": COSTO_COMPRA,\n",
    "        \"Cantidad\": CANTIDAD_COMPRA\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_compras.rename(columns=mapeo_columnas_compras, inplace=True)\n",
    "    df_compras = validar_datos_numericos_dataframe(df_compras, [COSTO_COMPRA, CANTIDAD_COMPRA])\n",
    "    # Calcular el 16% y sumarlo a la columna Costo_Compra\n",
    "    df_compras[COSTO_COMPRA] = df_compras[COSTO_COMPRA]+(df_compras[COSTO_COMPRA]*IVA)\n",
    "    #Fusionamos las ventas de accesorios, telefonía y refacciones\n",
    "    return df_compras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_compras_totales(df_compras):\n",
    "    df_compras = filtrar_columnas_dataframe(df_compras, [PROD_CONCAT, COSTO_COMPRA, CANTIDAD_COMPRA])\n",
    "    df_compras = df_compras.groupby([PROD_CONCAT]).agg({\n",
    "        CANTIDAD_COMPRA: 'sum',                 # Sumar las cantidades\n",
    "        COSTO_COMPRA: 'mean', #Promediar costos\n",
    "    }).reset_index()  # Resetear el índice para mantener las columnas de agrupación\n",
    "    return df_compras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_ventas_by_n1_y_utilidad(df, n1, registros, group_n= N2,  asc_ventas=False, asc_utilidad=True):\n",
    "    \"\"\"\n",
    "    Filtra el DataFrame para devolver los n registros con las mayores ventas globales\n",
    "    y menor utilidad, pero solo dentro del subconjunto filtrado por N1.\n",
    "\n",
    "    :param df: DataFrame con las columnas 'Venta Global', 'UTILIDAD', 'N1' y 'N2'.\n",
    "    :param n1: Valor de la columna N1 para filtrar los datos.\n",
    "    :param n: Número de registros a devolver por cada valor único de N2.\n",
    "    :return: DataFrame con los registros filtrados.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que el DataFrame tenga las columnas necesarias\n",
    "        columnas_requeridas = ['Venta Global', UTILIDAD, N1, N2]\n",
    "        for columna in columnas_requeridas:\n",
    "            if columna not in df.columns:\n",
    "                raise ValueError(f\"El DataFrame no contiene la columna requerida: {columna}\")\n",
    "\n",
    "        # Filtrar el DataFrame solo para los registros que coincidan con el valor de N1\n",
    "        df_filtrado_n1 = df[df[N1] == n1]\n",
    "\n",
    "        # Verificar si hay registros después del filtrado\n",
    "        if df_filtrado_n1.empty:\n",
    "            print(f\"No se encontraron registros para N1 = {n1}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Ordenar el DataFrame por 'Venta Global' (descendente) y 'UTILIDAD' (ascendente)\n",
    "        df_ordenado = df_filtrado_n1.sort_values(by=['Venta Global', UTILIDAD], ascending=[asc_ventas, asc_utilidad])\n",
    "\n",
    "        # Tomar los primeros n registros por cada valor único de N2\n",
    "        df_filtrado_final = df_ordenado.groupby(group_n).head(registros)\n",
    "\n",
    "        return df_filtrado_final\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al filtrar ventas con baja utilidad: {e}\")\n",
    "        return pd.DataFrame()  # Retornar DataFrame vacío en caso de error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_grafica_ventas_utilidad_por_categoria(df, columna_categoria='N2', nombre_pdf=\"reporte_ventas_utilidad.pdf\"):\n",
    "    \"\"\"\n",
    "    Genera gráficas de barras separadas por la categoría especificada ('N2' o 'N3'),\n",
    "    mostrando 'ProdConcat' en el eje X y 'Venta Global' en el eje Y. Se añade 'UTILIDAD_%'\n",
    "    como etiqueta dentro de cada barra. Se ajusta el tamaño de los labels del eje X.\n",
    "\n",
    "    :param df: DataFrame que contiene las columnas 'ProdConcat', 'Venta Global', 'UTILIDAD_%' y una columna de categoría (N2 o N3).\n",
    "    :param columna_categoria: Columna por la que se segmentarán las gráficas ('N2' o 'N3').\n",
    "    :param nombre_pdf: Nombre del archivo PDF de salida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas necesarias existan\n",
    "        columnas_requeridas = [PROD_CONCAT, 'Venta Global', UTILIDAD, columna_categoria]\n",
    "        for columna in columnas_requeridas:\n",
    "            if columna not in df.columns:\n",
    "                raise ValueError(f\"El DataFrame no contiene la columna requerida: {columna}\")\n",
    "\n",
    "        # Crear el archivo PDF para almacenar las gráficas\n",
    "        with PdfPages(nombre_pdf) as pdf:\n",
    "            # Obtener los valores únicos de la columna de categoría (N2 o N3)\n",
    "            categorias_unicas = df[columna_categoria].unique()\n",
    "\n",
    "            # Generar una gráfica por cada valor único de la columna de categoría\n",
    "            for categoria in categorias_unicas:\n",
    "                # Filtrar el DataFrame por la categoría actual\n",
    "                df_categoria = df[df[columna_categoria] == categoria]\n",
    "\n",
    "                # Ordenar por ventas globales para mejor visualización\n",
    "                df_categoria = df_categoria.sort_values(by='Venta Global', ascending=False)\n",
    "\n",
    "                # Crear una figura para la gráfica\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                barras = plt.bar(df_categoria[PROD_CONCAT], df_categoria['Venta Global'], color='skyblue')\n",
    "\n",
    "                # Añadir etiquetas de utilidad dentro de las barras\n",
    "                for barra, utilidad in zip(barras, df_categoria[UTILIDAD]):\n",
    "                    plt.text(\n",
    "                        barra.get_x() + barra.get_width() / 2,\n",
    "                        barra.get_height() / 2,\n",
    "                        f\"Utilidad={utilidad:.2f}%\",\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        fontsize=6,\n",
    "                        color='black'\n",
    "                    )\n",
    "\n",
    "                # Configuración de etiquetas y título\n",
    "                plt.title(f\"Ventas Globales - Categoría: {categoria}\", fontsize=14)\n",
    "                plt.xlabel(\"Producto\")\n",
    "                plt.ylabel(\"Venta Global\")\n",
    "\n",
    "                # Obtener el texto hasta el primer ' -' de cada ProdConcat\n",
    "                labels_reducidos = df_categoria[PROD_CONCAT].str.split(' -').str[0]\n",
    "\n",
    "                # Ajustar el tamaño de los labels del eje X y rotarlos\n",
    "                plt.xticks(rotation=45, ha='right', fontsize=8)  # Reducir tamaño de letra\n",
    "                plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Guardar la gráfica en el PDF\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            print(f\"Gráficas generadas y guardadas en: {nombre_pdf}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar las gráficas: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generar_grafica_utilidad_con_ventas_por_categoria(df, columna_categoria='N2', nombre_pdf=\"reporte_utilidad_ventas.pdf\"):\n",
    "    \"\"\"\n",
    "    Genera gráficas de barras separadas por la categoría especificada ('N2' o 'N3'),\n",
    "    mostrando 'ProdConcat' en el eje X y 'UTILIDAD_%' en el eje Y. Se añade 'Venta Global'\n",
    "    como etiqueta dentro de cada barra. Se ajusta el tamaño de los labels del eje X.\n",
    "\n",
    "    :param df: DataFrame que contiene las columnas 'ProdConcat', 'Venta Global', 'UTILIDAD_%' y una columna de categoría (N2 o N3).\n",
    "    :param columna_categoria: Columna por la que se segmentarán las gráficas ('N2' o 'N3').\n",
    "    :param nombre_pdf: Nombre del archivo PDF de salida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas necesarias existan\n",
    "        columnas_requeridas = [PROD_CONCAT, 'Venta Global', UTILIDAD, columna_categoria]\n",
    "        for columna in columnas_requeridas:\n",
    "            if columna not in df.columns:\n",
    "                raise ValueError(f\"El DataFrame no contiene la columna requerida: {columna}\")\n",
    "\n",
    "        # Crear el archivo PDF para almacenar las gráficas\n",
    "        with PdfPages(nombre_pdf) as pdf:\n",
    "            # Obtener los valores únicos de la columna de categoría (N2 o N3)\n",
    "            categorias_unicas = df[columna_categoria].unique()\n",
    "\n",
    "            # Generar una gráfica por cada valor único de la columna de categoría\n",
    "            for categoria in categorias_unicas:\n",
    "                # Filtrar el DataFrame por la categoría actual\n",
    "                df_categoria = df[df[columna_categoria] == categoria]\n",
    "\n",
    "                # Ordenar por utilidad (%) para priorizar productos con menor utilidad\n",
    "                df_categoria = df_categoria.sort_values(by=UTILIDAD, ascending=False)\n",
    "\n",
    "                # Crear una figura para la gráfica\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                barras = plt.bar(df_categoria[PROD_CONCAT], df_categoria[UTILIDAD], color='orange')\n",
    "\n",
    "                # Añadir etiquetas de venta global dentro de las barras\n",
    "                for barra, venta in zip(barras, df_categoria['Venta Global']):\n",
    "                    plt.text(\n",
    "                        barra.get_x() + barra.get_width() / 2,\n",
    "                        barra.get_height() / 2,\n",
    "                        f\"Unidades={venta:,.2f}\",  # Muestra venta global con formato de miles\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        fontsize=6,\n",
    "                        color='black'\n",
    "                    )\n",
    "\n",
    "                # Configuración de etiquetas y título\n",
    "                plt.title(f\"Utilidad % - Categoría: {categoria}\", fontsize=14)\n",
    "                plt.xlabel(\"Producto\")\n",
    "                plt.ylabel(\"Utilidad %\")\n",
    "\n",
    "                # Reducir el texto de 'ProdConcat' tomando solo hasta el primer ' -'\n",
    "                labels_reducidos = df_categoria[PROD_CONCAT].str.split(' -').str[0]\n",
    "\n",
    "                # Ajustar el tamaño de los labels del eje X y rotarlos\n",
    "                plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "                plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Guardar la gráfica en el PDF\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            print(f\"Gráficas generadas y guardadas en: {nombre_pdf}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Manejo de errores y notificación del problema\n",
    "        print(f\"Error al generar las gráficas: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceros reemplazados por NaN en las columnas: ['Cantidad', 'PrecioVenta']\n",
      "Ceros reemplazados por NaN en las columnas: ['Cantidad', 'PrecioVenta']\n",
      "Ceros reemplazados por NaN en las columnas: ['Costo Compra', 'Cantidad Compra']\n",
      "Archivo Excel generado exitosamente: BI-DATA-TRATADA-SIN-FILTROS_2024-12-23T22-58-30.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MAX-VENTAS-ACCESORIOS.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MIN-UTILIDAD-ACCESORIOS.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MAX-VENTAS-TELEFONIA.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MIN-UTILIDAD-TELEFONIA.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\2460073695.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)  # Labels aún más pequeños\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MAX-VENTAS-REFACCIONES.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n",
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_3780\\3079940885.py:57: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  plt.gca().set_xticklabels(labels_reducidos, fontsize=7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficas generadas y guardadas en: BI-MIN-UTILIDAD-REFACCIONES.pdf\n"
     ]
    }
   ],
   "source": [
    "#INICIO DE PROGRAMA\n",
    "\n",
    "#Dataframes iniciales (No los mutamos para poder usarlos)\n",
    "df_ventas = obtener_dataframe_ventas()\n",
    "df_compras = obtener_dataframe_compras()\n",
    "\n",
    "#Dataframe que muestra la cantidad de ventas por almacen como columnas para cada producto\n",
    "df_ventas_pivote_almacenes = df_ventas_pivot_almacen(df_ventas.copy(deep=True))\n",
    "\n",
    "#Dataframe que contiene la sumatoria de las ventas de un producto sin importar el almacen\n",
    "df_ventas_totales = df_ventas_totales(df_ventas.copy(deep=True))\n",
    "\n",
    "# Realizar el merge entre df_ventas_pivote_almacenes y df_ventas_totales por ProdConcat\n",
    "df_ventas_final = pd.merge(\n",
    "    df_ventas_pivote_almacenes,  # DataFrame de ventas pivoteadas por almacén\n",
    "    df_ventas_totales,           # DataFrame de ventas totales\n",
    "    on=PROD_CONCAT,             # Clave de unión (ProdConcat)\n",
    "    how=\"inner\"                  # Tipo de merge (inner join)\n",
    ")\n",
    "\n",
    "#Dataframe que tiene la sumatoria de las compras por productos sin importar el almacen\n",
    "df_compras_agrupadas = df_compras_totales(df_compras.copy(deep=True))\n",
    "\n",
    "# Realizar el merge entre df_ventas_final y df_compras_agrupadas por ProdConcat\n",
    "df_compras_ventas = pd.merge(\n",
    "    df_ventas_final,  # DataFrame de ventas pivoteadas por almacén\n",
    "    df_compras_agrupadas,           # DataFrame de ventas totales\n",
    "    on=PROD_CONCAT,             # Clave de unión (ProdConcat)\n",
    "    how=\"inner\"                  # Tipo de merge (inner join)\n",
    ")\n",
    "\n",
    "# Calcular la utilidad en porcentaje\n",
    "df_compras_ventas[UTILIDAD] = ((df_compras_ventas[PRECIO_VENTA] - df_compras_ventas[COSTO_COMPRA]) / df_compras_ventas[COSTO_COMPRA]) * CIEN\n",
    "\n",
    "generar_excel_by_dataframe(df_compras_ventas, \"BI-DATA-TRATADA-SIN-FILTROS\")\n",
    "\n",
    "df_compras_ventas = ordenar_columnas_al_lado(df_compras_ventas, PROD_CONCAT, [N1,N2,N3])\n",
    "TOP_REGISTROS= 8\n",
    "df_max_ventas_acc = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"INNOVACION MOVIL\", registros=TOP_REGISTROS, group_n=N3, asc_ventas=False, asc_utilidad=True)\n",
    "df_min_utilidad_acc = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"INNOVACION MOVIL\", registros=TOP_REGISTROS, group_n=N3, asc_ventas=True, asc_utilidad=True)\n",
    "df_max_ventas_tel = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"TECNOLOGIA MOVIL\", registros=TOP_REGISTROS, group_n=N2, asc_ventas=False, asc_utilidad=True)\n",
    "df_min_utilidad_tel = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"TECNOLOGIA MOVIL\", registros=TOP_REGISTROS, group_n=N2, asc_ventas=True, asc_utilidad=True)\n",
    "df_max_ventas_refacc = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"SOLUCIONES TECNICAS\", registros=TOP_REGISTROS, group_n=N2, asc_ventas=False, asc_utilidad=True)\n",
    "df_min_utilidad_refacc = filtrar_ventas_by_n1_y_utilidad(df_compras_ventas.copy(deep=True), n1=\"SOLUCIONES TECNICAS\", registros=TOP_REGISTROS, group_n=N2, asc_ventas=True, asc_utilidad=True)\n",
    "\n",
    "generar_grafica_ventas_utilidad_por_categoria(df=df_max_ventas_acc, columna_categoria=N3, nombre_pdf=\"BI-MAX-VENTAS-ACCESORIOS.pdf\")\n",
    "generar_grafica_utilidad_con_ventas_por_categoria(df=df_min_utilidad_acc, columna_categoria=N3, nombre_pdf=\"BI-MIN-UTILIDAD-ACCESORIOS.pdf\")\n",
    "generar_grafica_ventas_utilidad_por_categoria(df=df_max_ventas_tel, columna_categoria=N2, nombre_pdf=\"BI-MAX-VENTAS-TELEFONIA.pdf\")\n",
    "generar_grafica_utilidad_con_ventas_por_categoria(df=df_min_utilidad_tel, columna_categoria=N2, nombre_pdf=\"BI-MIN-UTILIDAD-TELEFONIA.pdf\")\n",
    "generar_grafica_ventas_utilidad_por_categoria(df=df_max_ventas_refacc, columna_categoria=N2, nombre_pdf=\"BI-MAX-VENTAS-REFACCIONES.pdf\")\n",
    "generar_grafica_utilidad_con_ventas_por_categoria(df=df_min_utilidad_refacc, columna_categoria=N2, nombre_pdf=\"BI-MIN-UTILIDAD-REFACCIONES.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
